{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = \"1\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.quantizers import Quantizer\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.quantize_config import QuantizeConfig\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.quantizers import LastValueQuantizer, MovingAverageQuantizer\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.quantize import quantize_annotate_layer, quantize_apply\n",
    "from tensorflow_model_optimization.quantization.keras import quantize_apply, quantize_scope\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.python.profiler import model_analyzer\n",
    "from tensorflow.python.profiler import option_builder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#Generate test data:\n",
    "X=np.random.rand(10000,5)\n",
    "y = np.sum(X, axis=1)\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedRangeQuantizer(Quantizer):\n",
    "    def build(self, tensor_shape, name, layer):\n",
    "        range_var = layer.add_weight(\n",
    "            name=name + '_range',\n",
    "            initializer=tf.keras.initializers.Constant(6.0),\n",
    "            trainable=False\n",
    "        )\n",
    "        return {'range_var': range_var}\n",
    "\n",
    "    def __call__(self, inputs, training, weights, **kwargs):\n",
    "        return tf.keras.backend.clip(inputs, 0.0, weights['range_var'])\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomLayerQuantizeConfig(QuantizeConfig):\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "        return [\n",
    "        (layer.kernel, LastValueQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False)),\n",
    "        (layer.bias,   LastValueQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False)),\n",
    "    ]\n",
    "\n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "        #return []\n",
    "        return [(layer.activation, MovingAverageQuantizer(num_bits=8, symmetric=False, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "        layer.kernel = quantize_weights[0]\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "        layer.activation = quantize_activations[0]\n",
    "\n",
    "    def get_output_quantizers(self, layer):\n",
    "        return [MovingAverageQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False)]\n",
    "        #return []\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "    layers.Dense(1024, activation='relu', input_shape=(5,)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    quantize_annotate_layer(layers.Dense(1024, activation='relu', input_shape=(5,)), quantize_config=CustomLayerQuantizeConfig()),\n",
    "    quantize_annotate_layer(layers.Dense(512, activation='relu'), quantize_config=CustomLayerQuantizeConfig()),\n",
    "    quantize_annotate_layer(layers.Dense(256, activation='relu'), quantize_config=CustomLayerQuantizeConfig()),\n",
    "    quantize_annotate_layer(layers.Dense(128, activation='relu'), quantize_config=CustomLayerQuantizeConfig()),\n",
    "    quantize_annotate_layer(layers.Dense(64, activation='relu'), quantize_config=CustomLayerQuantizeConfig()),\n",
    "    quantize_annotate_layer(layers.Dense(1, activation='relu'), quantize_config=CustomLayerQuantizeConfig()),\n",
    "    #layers.Dense(100, activation='relu', input_shape=(5,)),\n",
    "    #layers.Dense(1, activation='relu')\n",
    "])\n",
    "with quantize_scope({'CustomLayerQuantizeConfig': CustomLayerQuantizeConfig}):\n",
    "    quant_aware_model = quantize_apply(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "end_step = epochs * 100\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0,    # start training with 0% sparsity\n",
    "        final_sparsity=0.50,     # end training with 50% sparsity\n",
    "        begin_step=0,            # when to start pruning\n",
    "        end_step=end_step        # when to end pruning\n",
    "    )\n",
    "}\n",
    "\n",
    "# Wrap the original model\n",
    "model2 = tfmot.sparsity.keras.prune_low_magnitude(model2, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/313 [..............................] - ETA: 7:05 - loss: 7.0823 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0453s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0453s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 2ms/step - loss: 0.1197 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 4.0469e-05 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5773e-05 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 9.7975e-06 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 6.4866e-06 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 6.0859e-06 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 4.9187e-06 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 3.8703e-06 - accuracy: 0.0000e+00\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 2s 3ms/step - loss: 0.1251 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 8.0278e-04 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 9.1804e-04 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 6.6926e-04 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 7.6841e-04 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 9.0109e-04 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x770b103aae00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "]\n",
    "\n",
    "model2.fit(X, y,callbacks=callbacks, epochs=epochs)\n",
    "quant_aware_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "quant_aware_model.fit(X, y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tfmot.sparsity.keras.strip_pruning(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1.549348416433205\n",
      "[[1.5461711]]\n",
      "[[1.547096]]\n"
     ]
    }
   ],
   "source": [
    "vals=np.random.rand(1,5)\n",
    "result=np.sum(vals)\n",
    "prediction=quant_aware_model.predict(vals)\n",
    "prediction2=model2.predict(vals)\n",
    "print(result)\n",
    "print(prediction)\n",
    "print(prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(X.shape[0], 100, replace=False)\n",
    "x_random = X[index]\n",
    "def representative_data_gen():\n",
    "    # Here, let's use 100 samples for calibration\n",
    "    for i in range(100):\n",
    "        # The model expects (batch_size=1, 5) if it’s Dense(…, input_shape=(5,)).\n",
    "        # So we add a batch dimension of size 1:\n",
    "        yield [x_random[i:i+1].astype(np.float32)]  # shape (1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpul7emx20/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpul7emx20/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpycq8nebm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henrik/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1739700183.757227    4748 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1739700183.757239    4748 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-02-16 11:03:03.757328: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpul7emx20\n",
      "2025-02-16 11:03:03.759394: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-02-16 11:03:03.759405: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpul7emx20\n",
      "2025-02-16 11:03:03.776146: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-02-16 11:03:03.838784: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpul7emx20\n",
      "2025-02-16 11:03:03.855031: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 97704 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpycq8nebm/assets\n",
      "/home/henrik/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1739700184.209967    4748 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1739700184.209976    4748 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-02-16 11:03:04.210064: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpycq8nebm\n",
      "2025-02-16 11:03:04.210430: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-02-16 11:03:04.210437: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpycq8nebm\n",
      "2025-02-16 11:03:04.212948: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-02-16 11:03:04.224814: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpycq8nebm\n",
      "2025-02-16 11:03:04.228200: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 18138 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "quantconverter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(model2)\n",
    "\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter2.representative_dataset = representative_data_gen\n",
    "\n",
    "quantconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "quantconverter.representative_dataset = representative_data_gen\n",
    "quantlite=quantconverter.convert()\n",
    "lite2=converter2.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714344\n",
      "761032\n"
     ]
    }
   ],
   "source": [
    "#quant_aware_model.save('testfolder/8bit.h5')  # Save the model in HDF5 format\n",
    "#model2.save('testfolder/32bit.h5')  # Save the model in HDF5 format\n",
    "with open(\"testfolder/8bit.tflite\", \"wb\") as f:\n",
    "    f.write(quantlite)\n",
    "\n",
    "with open(\"testfolder/32bit.tflite\", \"wb\") as f:\n",
    "    f.write(lite2)\n",
    "\n",
    "# Get the size of the saved model file in bytes\n",
    "model_size = os.path.getsize('testfolder/8bit.tflite')\n",
    "print(model_size)\n",
    "\n",
    "model_size = os.path.getsize('testfolder/32bit.tflite')\n",
    "print(model_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before:\n",
    "714344\n",
    "761032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "\n",
    "with open(\"testfolder/8bit.tflite\", \"rb\") as f_in:\n",
    "    model_data = f_in.read()\n",
    "\n",
    "compressed_data = lzma.compress(model_data)\n",
    "\n",
    "with open(\"testfolder/8bit.tflite.xz\", \"wb\") as f_out:\n",
    "    f_out.write(compressed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testfolder/32bit.tflite\", \"rb\") as f_in:\n",
    "    model_data = f_in.read()\n",
    "\n",
    "compressed_data = lzma.compress(model_data)\n",
    "\n",
    "with open(\"testfolder/32bit.tflite.xz\", \"wb\") as f_out:\n",
    "    f_out.write(compressed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
